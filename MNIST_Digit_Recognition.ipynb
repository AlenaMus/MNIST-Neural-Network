{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Digit Recognition Neural Network\n",
    "\n",
    "**Description:** Educational implementation of a neural network that recognizes handwritten digits (0-9) using the MNIST dataset.\n",
    "\n",
    "**Purpose:** Learn fundamental concepts of deep learning including data preprocessing, neural network architecture, training, and evaluation.\n",
    "\n",
    "**Target Accuracy:** >95% on test set\n",
    "\n",
    "**Author:** AI Development Course - Lesson 36\n",
    "\n",
    "---\n",
    "\n",
    "## How to Run on Google Colab\n",
    "1. Go to **Runtime > Change runtime type** and select **T4 GPU** for faster training\n",
    "2. Run each cell sequentially from top to bottom\n",
    "3. Training takes < 1 minute on GPU, 3-5 minutes on CPU\n",
    "\n",
    "## Neural Network Architecture\n",
    "```\n",
    "Input:    784 neurons  (28x28 flattened image)\n",
    "  |\n",
    "Hidden 1: 128 neurons  (ReLU activation)\n",
    "  |\n",
    "Hidden 2:  64 neurons  (ReLU activation)\n",
    "  |\n",
    "Output:    10 neurons  (Softmax activation) -> digits 0-9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Imports and GPU Configuration\n",
    "This cell imports all required libraries and configures GPU acceleration.\n",
    "GPU acceleration significantly speeds up neural network training (minutes -> seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 1: Imports and GPU Configuration\n",
    "# ============================================\n",
    "\n",
    "# Core Deep Learning Framework\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Numerical Operations\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt          # For plotting graphs and displaying images\n",
    "import seaborn as sns                    # For beautiful confusion matrix heatmaps\n",
    "\n",
    "# Machine Learning Utilities\n",
    "from sklearn.metrics import confusion_matrix  # For evaluating prediction errors\n",
    "\n",
    "# Image Processing (for custom predictions)\n",
    "from PIL import Image                    # For loading and preprocessing custom images\n",
    "\n",
    "# System Utilities\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')        # Suppress warnings for cleaner output\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MNIST HANDWRITTEN DIGIT RECOGNITION\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# ============================================\n",
    "# GPU CONFIGURATION AND VERIFICATION\n",
    "# ============================================\n",
    "# WHY GPU? Neural networks perform millions of matrix operations. GPUs are designed\n",
    "# for parallel processing and can train models 10-100x faster than CPUs.\n",
    "#\n",
    "# What we're doing:\n",
    "# 1. Check if GPU is available\n",
    "# 2. Configure GPU memory growth (prevents out-of-memory errors)\n",
    "# 3. Print GPU information\n",
    "# ============================================\n",
    "\n",
    "print(\"Checking GPU availability...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Get list of all available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Configure GPU memory growth\n",
    "        # WHY? By default, TensorFlow allocates all GPU memory at once.\n",
    "        # Memory growth allows TensorFlow to allocate memory as needed,\n",
    "        # preventing crashes and allowing multiple programs to use the GPU.\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "        # Print GPU information\n",
    "        print(f\"\\u2713 GPU DETECTED: {len(gpus)} GPU(s) available\")\n",
    "        for i, gpu in enumerate(gpus):\n",
    "            print(f\"  GPU {i}: {gpu.name}\")\n",
    "        print()\n",
    "        print(\"GPU will be used for training (10-100x faster than CPU)\")\n",
    "        print(\"Expected training time: < 1 minute for 10 epochs\")\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU configuration error: {e}\")\n",
    "        print(\"Falling back to CPU...\")\n",
    "else:\n",
    "    print(\"\\u26a0 NO GPU DETECTED - Using CPU\")\n",
    "    print(\"Training will be slower (~2-5 minutes for 10 epochs)\")\n",
    "    print()\n",
    "    print(\"To enable GPU in Colab:\")\n",
    "    print(\"  Go to Runtime > Change runtime type > T4 GPU\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Load MNIST Dataset\n",
    "MNIST (Modified National Institute of Standards and Technology) is a classic dataset of 70,000 handwritten digit images (0-9).\n",
    "\n",
    "**Dataset Structure:**\n",
    "- Training set: 60,000 images (used to train the model)\n",
    "- Test set: 10,000 images (used to evaluate final performance)\n",
    "- Image format: 28x28 pixels, grayscale (1 channel)\n",
    "- Pixel values: 0-255 (0=black, 255=white)\n",
    "- Labels: 0-9 (which digit the image represents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 2: Load MNIST Dataset\n",
    "# ============================================\n",
    "\n",
    "print(\"LOADING MNIST DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load the MNIST dataset\n",
    "# This function returns 4 arrays:\n",
    "# - X_train: Training images (60000, 28, 28)\n",
    "# - y_train: Training labels (60000,)\n",
    "# - X_test: Test images (10000, 28, 28)\n",
    "# - y_test: Test labels (10000,)\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Display dataset information\n",
    "print(f\"\\u2713 Dataset loaded successfully!\")\n",
    "print()\n",
    "print(\"Dataset Statistics:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Training Images: {X_train.shape[0]:,} samples\")\n",
    "print(f\"  Shape: {X_train.shape} (samples, height, width)\")\n",
    "print(f\"  Pixel value range: {X_train.min()} to {X_train.max()}\")\n",
    "print()\n",
    "print(f\"Training Labels: {y_train.shape[0]:,} samples\")\n",
    "print(f\"  Label range: {y_train.min()} to {y_train.max()} (digits 0-9)\")\n",
    "print()\n",
    "print(f\"Test Images: {X_test.shape[0]:,} samples\")\n",
    "print(f\"  Shape: {X_test.shape}\")\n",
    "print()\n",
    "print(f\"Test Labels: {y_test.shape[0]:,} samples\")\n",
    "print()\n",
    "print(\"Each image:\")\n",
    "print(f\"  - Resolution: 28\\u00d728 pixels (784 total pixels)\")\n",
    "print(f\"  - Color: Grayscale (single channel)\")\n",
    "print(f\"  - Format: White digit on black background\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Preview Sample Images (Digits 6-9)\n",
    "Visualizing the data helps us understand what we're working with.\n",
    "\n",
    "**Why visualize?**\n",
    "- Verify data loaded correctly\n",
    "- Understand image quality and variation\n",
    "- See what the model needs to learn to distinguish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 3: Preview Sample Images (Digits 6-9)\n",
    "# ============================================\n",
    "\n",
    "print(\"PREVIEWING SAMPLE DIGITS (6, 7, 8, 9)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a figure with 2x2 subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "fig.suptitle('Sample MNIST Digits: 6, 7, 8, 9', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Digits we want to display\n",
    "target_digits = [6, 7, 8, 9]\n",
    "\n",
    "# Find and display one sample of each digit\n",
    "for idx, digit in enumerate(target_digits):\n",
    "    # Find the first occurrence of this digit in training set\n",
    "    # np.where returns indices where condition is True\n",
    "    sample_index = np.where(y_train == digit)[0][0]\n",
    "\n",
    "    # Get the image\n",
    "    sample_image = X_train[sample_index]\n",
    "\n",
    "    # Calculate subplot position (row, col)\n",
    "    row = idx // 2  # 0, 0, 1, 1\n",
    "    col = idx % 2   # 0, 1, 0, 1\n",
    "\n",
    "    # Display the image\n",
    "    axes[row, col].imshow(sample_image, cmap='gray')\n",
    "    axes[row, col].set_title(f'Digit: {digit}', fontsize=14, fontweight='bold')\n",
    "    axes[row, col].axis('off')  # Hide axis for cleaner display\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\u2713 Sample images displayed successfully\")\n",
    "print(\"  Notice: Images are 28\\u00d728 pixels, grayscale\")\n",
    "print(\"  White pixels = digit, Black pixels = background\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Data Preprocessing\n",
    "Raw data needs preprocessing before feeding to neural network. Three critical steps:\n",
    "\n",
    "1. **Normalization** - Scale pixel values from [0-255] to [0.0-1.0]\n",
    "2. **Flattening** - Convert 2D images (28x28) to 1D vectors (784)\n",
    "3. **One-Hot Encoding** - Convert integer labels to categorical vectors\n",
    "\n",
    "### Why each step matters:\n",
    "- **Normalization:** Large values cause unstable gradients and slow convergence\n",
    "- **Flattening:** Dense layers require 1D input vectors\n",
    "- **One-Hot Encoding:** Prevents the model from interpreting labels as ordered values (e.g., 9 > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 4: Data Preprocessing\n",
    "# ============================================\n",
    "\n",
    "print(\"DATA PREPROCESSING\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# ============================================\n",
    "# STEP 4.1: NORMALIZATION\n",
    "# ============================================\n",
    "# WHY NORMALIZE?\n",
    "# - Original pixel values: 0-255 (integers)\n",
    "# - Neural networks learn better with smaller values (0-1 range)\n",
    "# - Large values can cause:\n",
    "#   1. Unstable gradients during training\n",
    "#   2. Slow convergence\n",
    "#   3. Numerical overflow/underflow\n",
    "#\n",
    "# HOW? Divide all pixel values by 255.0\n",
    "# Result: Values now in range [0.0, 1.0]\n",
    "# ============================================\n",
    "\n",
    "print(\"Step 1: NORMALIZATION\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Converting pixel values from [0-255] to [0.0-1.0]\")\n",
    "print()\n",
    "print(f\"Before normalization:\")\n",
    "print(f\"  Min value: {X_train.min()}, Max value: {X_train.max()}\")\n",
    "print(f\"  Data type: {X_train.dtype}\")\n",
    "\n",
    "# Normalize by dividing by 255.0\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "print()\n",
    "print(f\"After normalization:\")\n",
    "print(f\"  Min value: {X_train.min():.4f}, Max value: {X_train.max():.4f}\")\n",
    "print(f\"  Data type: {X_train.dtype}\")\n",
    "print(\"\\u2713 Normalization complete\")\n",
    "print()\n",
    "\n",
    "# ============================================\n",
    "# STEP 4.2: FLATTENING\n",
    "# ============================================\n",
    "# WHY FLATTEN?\n",
    "# - Current shape: (60000, 28, 28) - 2D images\n",
    "# - Dense layers need 1D input: (60000, 784)\n",
    "# - 28 x 28 = 784 pixels per image\n",
    "# ============================================\n",
    "\n",
    "print(\"Step 2: FLATTENING\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Converting 2D images (28\\u00d728) to 1D vectors (784)\")\n",
    "print()\n",
    "print(f\"Before flattening:\")\n",
    "print(f\"  Training shape: {X_train.shape}\")\n",
    "print(f\"  Test shape: {X_test.shape}\")\n",
    "\n",
    "# Reshape from (num_samples, 28, 28) to (num_samples, 784)\n",
    "X_train = X_train.reshape(X_train.shape[0], 28 * 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28 * 28)\n",
    "\n",
    "print()\n",
    "print(f\"After flattening:\")\n",
    "print(f\"  Training shape: {X_train.shape}\")\n",
    "print(f\"  Test shape: {X_test.shape}\")\n",
    "print(f\"  Each image is now a vector of {X_train.shape[1]} pixel values\")\n",
    "print(\"\\u2713 Flattening complete\")\n",
    "print()\n",
    "\n",
    "# ============================================\n",
    "# STEP 4.3: ONE-HOT ENCODING\n",
    "# ============================================\n",
    "# WHY ONE-HOT ENCODE?\n",
    "# - Current labels: Single integers (0, 1, 2, ..., 9)\n",
    "# - Problem: Neural networks interpret these as ordered values\n",
    "# - Solution: One-hot encoding - each class gets its own dimension\n",
    "#\n",
    "# How it works:\n",
    "# - Label 0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "# - Label 1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "# - Label 3 -> [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "# - Label 9 -> [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "# ============================================\n",
    "\n",
    "print(\"Step 3: ONE-HOT ENCODING\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Converting integer labels to categorical vectors\")\n",
    "print()\n",
    "print(f\"Before one-hot encoding:\")\n",
    "print(f\"  Training labels shape: {y_train.shape}\")\n",
    "print(f\"  Sample labels: {y_train[:10]}\")\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print()\n",
    "print(f\"After one-hot encoding:\")\n",
    "print(f\"  Training labels shape: {y_train.shape}\")\n",
    "print(f\"  Sample label (first image):\")\n",
    "print(f\"    {y_train[0]}\")\n",
    "print(f\"    \\u2191 Position with '1' indicates the digit class\")\n",
    "print(\"\\u2713 One-hot encoding complete\")\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"\\u2713 ALL PREPROCESSING COMPLETE\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Build Neural Network Architecture\n",
    "\n",
    "We build a fully connected (Dense) neural network:\n",
    "\n",
    "| Layer | Neurons | Activation | Parameters | Purpose |\n",
    "|-------|---------|------------|------------|---------|\n",
    "| Hidden 1 | 128 | ReLU | 100,480 | Feature extraction |\n",
    "| Hidden 2 | 64 | ReLU | 8,256 | Feature combination |\n",
    "| Output | 10 | Softmax | 650 | Classification |\n",
    "\n",
    "**Why this architecture?**\n",
    "- **Funnel Shape (784->128->64->10):** Forces network to learn compressed features\n",
    "- **ReLU:** Fast, prevents vanishing gradients\n",
    "- **Softmax:** Outputs probabilities summing to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 5: Build Neural Network Architecture\n",
    "# ============================================\n",
    "\n",
    "print(\"BUILDING NEURAL NETWORK ARCHITECTURE\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Create Sequential model (layers stacked in sequence)\n",
    "model = Sequential([\n",
    "\n",
    "    # HIDDEN LAYER 1: 128 neurons with ReLU\n",
    "    # Input: 784 features (flattened 28x28 image)\n",
    "    # Output: 128 features\n",
    "    # Parameters: 784 x 128 + 128 (bias) = 100,480\n",
    "    #\n",
    "    # WHY ReLU (Rectified Linear Unit)?\n",
    "    # - Formula: ReLU(x) = max(0, x)\n",
    "    # - Fast to compute (just max operation)\n",
    "    # - Prevents vanishing gradient problem\n",
    "    # - Introduces non-linearity (allows learning complex patterns)\n",
    "    Dense(128, activation='relu', input_shape=(784,), name='hidden_layer_1'),\n",
    "\n",
    "    # HIDDEN LAYER 2: 64 neurons with ReLU\n",
    "    # Input: 128 features from previous layer\n",
    "    # Output: 64 features\n",
    "    # Parameters: 128 x 64 + 64 (bias) = 8,256\n",
    "    #\n",
    "    # Layer 1: Low-level features (edges, strokes)\n",
    "    # Layer 2: High-level features (curves, loops, digit shapes)\n",
    "    Dense(64, activation='relu', name='hidden_layer_2'),\n",
    "\n",
    "    # OUTPUT LAYER: 10 neurons with Softmax\n",
    "    # Input: 64 features from previous layer\n",
    "    # Output: 10 probabilities (one per digit 0-9)\n",
    "    # Parameters: 64 x 10 + 10 (bias) = 650\n",
    "    #\n",
    "    # WHY Softmax?\n",
    "    # - Converts raw scores to probabilities (sum = 1.0)\n",
    "    # - Perfect for multi-class classification\n",
    "    # - Example: [0.01, 0.02, 0.03, 0.89, ...] -> 89% confident it's digit 3\n",
    "    Dense(10, activation='softmax', name='output_layer')\n",
    "])\n",
    "\n",
    "print(\"\\u2713 Model architecture created\")\n",
    "print()\n",
    "print(\"ARCHITECTURE SUMMARY:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Layer Structure (Funnel Design):\")\n",
    "print(\"  Input:    784 neurons  (28\\u00d728 flattened image)\")\n",
    "print(\"           \\u2193\")\n",
    "print(\"  Hidden 1: 128 neurons  (ReLU) - Feature extraction\")\n",
    "print(\"           \\u2193\")\n",
    "print(\"  Hidden 2:  64 neurons  (ReLU) - Feature combination\")\n",
    "print(\"           \\u2193\")\n",
    "print(\"  Output:    10 neurons  (Softmax) - Classification\")\n",
    "print()\n",
    "\n",
    "# Display detailed model summary\n",
    "print(\"DETAILED MODEL SUMMARY:\")\n",
    "print(\"-\" * 60)\n",
    "model.summary()\n",
    "\n",
    "total_params = model.count_params()\n",
    "print()\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(\"  These are the 'weights' that will be learned during training\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Compile Model\n",
    "Compilation configures the learning process:\n",
    "\n",
    "1. **Optimizer (Adam):** Algorithm that updates weights - combines momentum with adaptive learning rates\n",
    "2. **Loss (Categorical Crossentropy):** Measures how wrong predictions are - `Loss = -sum(y_true * log(y_pred))`\n",
    "3. **Metrics (Accuracy):** Performance measure to track - correct predictions / total predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 6: Compile Model\n",
    "# ============================================\n",
    "\n",
    "print(\"COMPILING THE MODEL\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# ============================================\n",
    "# OPTIMIZER: ADAM (Adaptive Moment Estimation)\n",
    "# ============================================\n",
    "# WHY ADAM?\n",
    "# - Best general-purpose optimizer for deep learning\n",
    "# - Combines momentum + adaptive learning rates\n",
    "# - Fast convergence with minimal hyperparameter tuning\n",
    "#\n",
    "# Default Hyperparameters:\n",
    "# - learning_rate = 0.001\n",
    "# - beta_1 = 0.9 (momentum decay)\n",
    "# - beta_2 = 0.999 (variance decay)\n",
    "# ============================================\n",
    "\n",
    "print(\"1. OPTIMIZER: Adam\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Adam (Adaptive Moment Estimation) is the gold-standard optimizer\")\n",
    "print()\n",
    "print(\"How it works:\")\n",
    "print(\"  - Standard SGD: weight = weight - learning_rate \\u00d7 gradient\")\n",
    "print(\"  - Adam: weight = weight - adaptive_lr \\u00d7 momentum_adjusted_gradient\")\n",
    "print()\n",
    "print(\"Key features:\")\n",
    "print(\"  \\u2713 Adaptive learning rates per parameter\")\n",
    "print(\"  \\u2713 Momentum (remembers past gradients)\")\n",
    "print(\"  \\u2713 Fast convergence\")\n",
    "print(\"  \\u2713 Minimal tuning needed\")\n",
    "print()\n",
    "\n",
    "# ============================================\n",
    "# LOSS FUNCTION: CATEGORICAL CROSSENTROPY\n",
    "# ============================================\n",
    "# Formula: Loss = -sum(y_true * log(y_pred))\n",
    "#\n",
    "# Good prediction (digit 3):  Loss = -log(0.85) = 0.163 (LOW)\n",
    "# Bad prediction (digit 3):   Loss = -log(0.01) = 4.605 (HIGH)\n",
    "# ============================================\n",
    "\n",
    "print(\"2. LOSS FUNCTION: Categorical Crossentropy\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Formula: Loss = -\\u03a3(y_true \\u00d7 log(y_pred))\")\n",
    "print()\n",
    "print(\"Example:\")\n",
    "print(\"  Good prediction: Loss = -log(0.85) = 0.163  \\u2190 LOW (good!)\")\n",
    "print(\"  Bad prediction:  Loss = -log(0.01) = 4.605  \\u2190 HIGH (bad!)\")\n",
    "print()\n",
    "\n",
    "print(\"3. METRICS: Accuracy\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Accuracy = Correct Predictions / Total Predictions\")\n",
    "print()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',                    # Adam optimizer with default params\n",
    "    loss='categorical_crossentropy',     # Loss function for multi-class\n",
    "    metrics=['accuracy']                 # Track accuracy during training\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"\\u2713 MODEL COMPILED SUCCESSFULLY\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Ready for training with:\")\n",
    "print(\"  Optimizer: Adam (learning_rate=0.001)\")\n",
    "print(\"  Loss: Categorical Crossentropy\")\n",
    "print(\"  Metric: Accuracy\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Train the Model\n",
    "\n",
    "Training is the process where the model learns to recognize digits:\n",
    "1. Show model a batch of images\n",
    "2. Model makes predictions\n",
    "3. Calculate loss (how wrong the predictions are)\n",
    "4. Backpropagation: Calculate gradients\n",
    "5. Optimizer updates weights to reduce loss\n",
    "6. Repeat!\n",
    "\n",
    "**Training Parameters:**\n",
    "- **Epochs:** 10 (complete passes through training data)\n",
    "- **Batch Size:** 32 (samples per weight update)\n",
    "- **Validation Split:** 10% (monitor overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 7: Train the Model\n",
    "# ============================================\n",
    "\n",
    "print(\"TRAINING THE MODEL\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Training Parameters\n",
    "EPOCHS = 10          # Number of complete passes through training data\n",
    "BATCH_SIZE = 32      # Number of samples per weight update\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(\"  \\u2192 The model will see the entire training dataset 10 times\")\n",
    "print()\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(\"  \\u2192 Process 32 images at a time before updating weights\")\n",
    "print()\n",
    "print(f\"Validation Split: 10%\")\n",
    "print(\"  \\u2192 Use 10% of training data to monitor overfitting\")\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"STARTING TRAINING...\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Train the model\n",
    "# history object stores metrics for each epoch\n",
    "history = model.fit(\n",
    "    X_train,                    # Training images (flattened, normalized)\n",
    "    y_train,                    # Training labels (one-hot encoded)\n",
    "    epochs=EPOCHS,              # Number of complete passes through data\n",
    "    batch_size=BATCH_SIZE,      # Samples per gradient update\n",
    "    validation_split=0.1,       # Use 10% of training data for validation\n",
    "    verbose=1                   # Display progress bar\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"\\u2713 TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"What just happened?\")\n",
    "print(\"  - Model saw 60,000 training images 10 times (10 epochs)\")\n",
    "print(\"  - Adjusted 109,386 parameters to minimize prediction error\")\n",
    "print(\"  - Loss decreased \\u2192 Model learned patterns in digit images\")\n",
    "print(\"  - Accuracy increased \\u2192 Model makes better predictions\")\n",
    "print()\n",
    "print(\"Notice the trend:\")\n",
    "print(\"  - Early epochs: Big improvements (learning basic patterns)\")\n",
    "print(\"  - Later epochs: Small improvements (refining understanding)\")\n",
    "print(\"  - Validation accuracy close to training = good generalization\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Evaluate Model on Test Set\n",
    "\n",
    "**Why test data?**\n",
    "- Test set contains images the model has **NEVER** seen\n",
    "- Measures real-world performance (generalization)\n",
    "- Training accuracy can be misleading (overfitting)\n",
    "\n",
    "**Overfitting vs. Generalization:**\n",
    "- **Overfitting:** Model memorizes training data, fails on new data\n",
    "- **Good generalization:** Model learns patterns, works on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 8: Evaluate Model\n",
    "# ============================================\n",
    "\n",
    "print(\"EVALUATING MODEL ON TEST SET\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"Why evaluate on test set?\")\n",
    "print(\"  - Test data was NEVER seen during training\")\n",
    "print(\"  - Measures real-world performance\")\n",
    "print(\"  - Detects overfitting (memorization vs. learning)\")\n",
    "print()\n",
    "print(\"Evaluating on 10,000 test images...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Evaluate model on test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print()\n",
    "\n",
    "# Interpret results\n",
    "if test_accuracy >= 0.97:\n",
    "    print(\"\\u2713 EXCELLENT! Model performs very well (\\u226597%)\")\n",
    "elif test_accuracy >= 0.95:\n",
    "    print(\"\\u2713 GOOD! Model meets target accuracy (\\u226595%)\")\n",
    "elif test_accuracy >= 0.90:\n",
    "    print(\"\\u26a0 ACCEPTABLE but below target (90-95%)\")\n",
    "else:\n",
    "    print(\"\\u2717 POOR performance (<90%) - Model needs improvement\")\n",
    "\n",
    "print()\n",
    "print(\"What does this mean?\")\n",
    "print(f\"  - Out of 10,000 test images, model correctly classifies\")\n",
    "print(f\"    approximately {int(test_accuracy * 10000):,} images\")\n",
    "print(f\"  - Error rate: {(1 - test_accuracy) * 100:.2f}%\")\n",
    "print()\n",
    "\n",
    "# Compare training vs test accuracy (check for overfitting)\n",
    "final_train_accuracy = history.history['accuracy'][-1]\n",
    "accuracy_gap = abs(final_train_accuracy - test_accuracy)\n",
    "\n",
    "print(\"Overfitting Check:\")\n",
    "print(f\"  Final Training Accuracy: {final_train_accuracy * 100:.2f}%\")\n",
    "print(f\"  Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"  Difference: {accuracy_gap * 100:.2f}%\")\n",
    "\n",
    "if accuracy_gap < 0.03:\n",
    "    print(\"  \\u2713 Good generalization (difference < 3%)\")\n",
    "elif accuracy_gap < 0.05:\n",
    "    print(\"  \\u26a0 Slight overfitting (difference 3-5%)\")\n",
    "else:\n",
    "    print(\"  \\u2717 Overfitting detected (difference > 5%)\")\n",
    "    print(\"    Model memorized training data instead of learning patterns\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Training History - Loss Curve\n",
    "\n",
    "**How to interpret:**\n",
    "- Both lines decreasing = Model is learning\n",
    "- Lines close together = Good generalization\n",
    "- Training << Validation = Overfitting\n",
    "- Both lines flat/high = Underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 9: Plot Training History (Loss Curve)\n",
    "# ============================================\n",
    "\n",
    "print(\"VISUALIZING TRAINING HISTORY - LOSS CURVE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.plot(history.history['loss'], marker='o', linestyle='-', linewidth=2,\n",
    "         label='Training Loss', color='#2E86AB')\n",
    "plt.plot(history.history['val_loss'], marker='s', linestyle='--', linewidth=2,\n",
    "         label='Validation Loss', color='#A23B72')\n",
    "\n",
    "plt.title('Model Loss Over Training Epochs', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Loss (Categorical Crossentropy)', fontsize=12, fontweight='bold')\n",
    "plt.legend(loc='upper right', fontsize=11, frameon=True, shadow=True)\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "plt.xticks(range(EPOCHS))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"How to interpret this graph:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\\u2713 Both lines decreasing = Model is learning\")\n",
    "print(\"\\u2713 Lines close together = Good generalization\")\n",
    "print(\"\\u2717 Training << Validation = Overfitting\")\n",
    "print(\"\\u2717 Both lines flat/high = Underfitting\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Training History - Accuracy Curve\n",
    "\n",
    "Accuracy is easier to interpret than loss (higher = better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 10: Plot Training History (Accuracy Curve)\n",
    "# ============================================\n",
    "\n",
    "print(\"VISUALIZING TRAINING HISTORY - ACCURACY CURVE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.plot(history.history['accuracy'], marker='o', linestyle='-', linewidth=2,\n",
    "         label='Training Accuracy', color='#06A77D')\n",
    "plt.plot(history.history['val_accuracy'], marker='s', linestyle='--', linewidth=2,\n",
    "         label='Validation Accuracy', color='#D4526E')\n",
    "\n",
    "plt.title('Model Accuracy Over Training Epochs', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=11, frameon=True, shadow=True)\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "plt.xticks(range(EPOCHS))\n",
    "plt.ylim([0.9, 1.0])  # Focus on 90-100% range\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"How to interpret this graph:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\\u2713 Both lines increasing = Model is learning\")\n",
    "print(\"\\u2713 Lines close together = Good generalization\")\n",
    "print(\"\\u2717 Training >> Validation = Overfitting\")\n",
    "print(\"\\u2022 Rapid improvement in early epochs (basic patterns)\")\n",
    "print(\"\\u2022 Slower improvement in later epochs (fine-tuning)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Confusion Matrix\n",
    "\n",
    "A confusion matrix shows which digits the model confuses with each other:\n",
    "- **Rows:** Actual/True labels\n",
    "- **Columns:** Predicted labels\n",
    "- **Diagonal:** Correct predictions (should be highest)\n",
    "- **Off-diagonal:** Misclassifications (errors)\n",
    "\n",
    "Common confusions: 4<->9, 3<->8, 5<->6, 7<->1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 11: Confusion Matrix\n",
    "# ============================================\n",
    "\n",
    "print(\"GENERATING CONFUSION MATRIX\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Generate predictions on test set\n",
    "y_pred_probs = model.predict(X_test, verbose=0)\n",
    "\n",
    "# Convert predictions from probabilities to class labels\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Convert true labels from one-hot to class labels\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "print(f\"\\u2713 Generated predictions for {len(y_test):,} test images\")\n",
    "print()\n",
    "\n",
    "# Visualize confusion matrix as heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "sns.heatmap(cm,\n",
    "            annot=True,              # Show numbers in cells\n",
    "            fmt='d',                 # Integer format\n",
    "            cmap='Blues',            # Color scheme\n",
    "            xticklabels=range(10),\n",
    "            yticklabels=range(10),\n",
    "            cbar_kws={'label': 'Number of Predictions'},\n",
    "            linewidths=0.5,\n",
    "            linecolor='gray')\n",
    "\n",
    "plt.title('Confusion Matrix - MNIST Test Set (10,000 images)',\n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicted Digit', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('True Digit', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"How to read the confusion matrix:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Diagonal: Correct predictions (darker = more correct)\")\n",
    "print(\"Off-diagonal: Misclassifications (errors)\")\n",
    "print()\n",
    "\n",
    "# Find most common confusion\n",
    "max_confusion = 0\n",
    "confused_pair = (0, 0)\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j and cm[i, j] > max_confusion:\n",
    "            max_confusion = cm[i, j]\n",
    "            confused_pair = (i, j)\n",
    "\n",
    "print(\"Most common confusion:\")\n",
    "print(f\"  Digit {confused_pair[0]} misclassified as {confused_pair[1]}: \"\n",
    "      f\"{max_confusion} times\")\n",
    "print()\n",
    "\n",
    "# Per-digit accuracy\n",
    "print(\"Per-digit accuracy:\")\n",
    "print(\"-\" * 60)\n",
    "for digit in range(10):\n",
    "    correct = cm[digit, digit]\n",
    "    total = cm[digit].sum()\n",
    "    digit_accuracy = correct / total * 100\n",
    "    print(f\"  Digit {digit}: {digit_accuracy:.2f}% ({correct}/{total} correct)\")\n",
    "\n",
    "print()\n",
    "print(\"Common confusions to look for:\")\n",
    "print(\"  - 4 \\u2194 9 (similar top parts)\")\n",
    "print(\"  - 3 \\u2194 8 (similar curves)\")\n",
    "print(\"  - 5 \\u2194 6 (similar shapes)\")\n",
    "print(\"  - 7 \\u2194 1 (similar strokes)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12: Custom Image Prediction Functions\n",
    "\n",
    "These functions allow you to predict digits from your own handwritten images.\n",
    "\n",
    "**Pipeline:**\n",
    "1. Load image -> Convert to grayscale -> Resize to 28x28\n",
    "2. Normalize to [0,1] -> Flatten to 784 -> Predict\n",
    "\n",
    "**Image requirements:**\n",
    "- Format: PNG, JPG, or JPEG\n",
    "- Content: Single handwritten digit (0-9)\n",
    "- Recommended: White digit on black background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 12: Custom Image Prediction Functions\n",
    "# ============================================\n",
    "\n",
    "print(\"CUSTOM IMAGE PREDICTION FUNCTIONS\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Preprocess a custom image to match MNIST format.\n",
    "\n",
    "    Pipeline:\n",
    "    1. Load image from file\n",
    "    2. Convert to grayscale (if RGB)\n",
    "    3. Resize to 28x28 pixels\n",
    "    4. Invert colors if needed (MNIST = white on black)\n",
    "    5. Normalize to [0, 1]\n",
    "    6. Flatten to 784-element vector\n",
    "    7. Reshape to (1, 784) for model input\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to image file\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Preprocessed image ready for prediction (1, 784)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        img = img.convert('L')  # Grayscale\n",
    "        img = img.resize((28, 28), Image.Resampling.LANCZOS)\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        # Invert colors if needed (MNIST = white on black)\n",
    "        # Uncomment if your image has black digit on white background:\n",
    "        # img_array = 255 - img_array\n",
    "\n",
    "        img_array = img_array.astype('float32') / 255.0\n",
    "        img_array = img_array.reshape(1, 784)\n",
    "        return img_array\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found - {image_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing image: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def predict_digit(model, image_path):\n",
    "    \"\"\"\n",
    "    Predict the digit in a custom image.\n",
    "\n",
    "    Args:\n",
    "        model: Trained Keras model\n",
    "        image_path (str): Path to image file\n",
    "\n",
    "    Returns:\n",
    "        tuple: (predicted_digit, confidence, all_probabilities)\n",
    "    \"\"\"\n",
    "    img_array = preprocess_image(image_path)\n",
    "    if img_array is None:\n",
    "        return None, None, None\n",
    "\n",
    "    predictions = model.predict(img_array, verbose=0)\n",
    "    predicted_digit = np.argmax(predictions[0])\n",
    "    confidence = predictions[0][predicted_digit] * 100\n",
    "    all_probabilities = predictions[0]\n",
    "\n",
    "    return predicted_digit, confidence, all_probabilities\n",
    "\n",
    "\n",
    "def display_prediction(image_path, digit, confidence, probabilities):\n",
    "    \"\"\"\n",
    "    Display the input image with prediction results.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Left: Original image\n",
    "    img = Image.open(image_path).convert('L')\n",
    "    ax1.imshow(img, cmap='gray')\n",
    "    ax1.set_title('Input Image', fontsize=14, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    # Right: Probability bar chart\n",
    "    ax2.bar(range(10), probabilities * 100, color='steelblue', alpha=0.7)\n",
    "    ax2.bar(digit, probabilities[digit] * 100, color='crimson', alpha=0.9)\n",
    "    ax2.set_xlabel('Digit', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Probability (%)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title(f'Prediction: {digit} (Confidence: {confidence:.2f}%)',\n",
    "                  fontsize=14, fontweight='bold')\n",
    "    ax2.set_xticks(range(10))\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "    print(\"=\" * 60)\n",
    "    print(\"PREDICTION RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Predicted Digit: {digit}\")\n",
    "    print(f\"Confidence: {confidence:.2f}%\")\n",
    "    print()\n",
    "    print(\"All class probabilities:\")\n",
    "    for i, prob in enumerate(probabilities):\n",
    "        marker = \" \\u2190 PREDICTED\" if i == digit else \"\"\n",
    "        print(f\"  Digit {i}: {prob * 100:5.2f}%{marker}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "print(\"\\u2713 Custom prediction functions defined:\")\n",
    "print(\"  - preprocess_image(image_path)\")\n",
    "print(\"  - predict_digit(model, image_path)\")\n",
    "print(\"  - display_prediction(image_path, digit, confidence, probabilities)\")\n",
    "print()\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 13: Test with a Custom Image (Google Colab)\n\n**3 ways to test your own digit:**\n\n| Method | How | Best For |\n|--------|-----|----------|\n| **A - Upload** | Click \"Choose Files\" button | Testing images from your computer |\n| **B - Draw** | Draw a digit with your mouse directly in the notebook | Quick testing, no files needed |\n| **C - Test Set** | Automatically picks a random test image | Quick demo, no input needed |\n\n**Important:** Most handwritten images have a **black digit on white background**, but MNIST expects **white digit on black background**. The code auto-inverts colors for you."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# CELL 13: Test with Custom Image - 3 Methods\n# ============================================\n# Method A: Upload image from your computer\n# Method B: Draw a digit directly in the notebook\n# Method C: Test with a random image from the test set\n# ============================================\n\nimport io\nimport base64\n\ndef predict_from_array(img_array_2d):\n    \"\"\"\n    Predict digit from a 28x28 numpy array.\n    Handles preprocessing: normalize, flatten, predict.\n    \"\"\"\n    # Show the image as the model sees it\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n\n    ax1.imshow(img_array_2d, cmap='gray')\n    ax1.set_title('Image (as model sees it)', fontsize=14, fontweight='bold')\n    ax1.axis('off')\n\n    # Normalize and flatten\n    img_flat = img_array_2d.astype('float32') / 255.0 if img_array_2d.max() > 1 else img_array_2d.astype('float32')\n    img_flat = img_flat.reshape(1, 784)\n\n    # Predict\n    predictions = model.predict(img_flat, verbose=0)\n    predicted_digit = np.argmax(predictions[0])\n    confidence = predictions[0][predicted_digit] * 100\n\n    # Probability bar chart\n    ax2.bar(range(10), predictions[0] * 100, color='steelblue', alpha=0.7)\n    ax2.bar(predicted_digit, predictions[0][predicted_digit] * 100, color='crimson', alpha=0.9)\n    ax2.set_xlabel('Digit', fontsize=12, fontweight='bold')\n    ax2.set_ylabel('Probability (%)', fontsize=12, fontweight='bold')\n    ax2.set_title(f'Prediction: {predicted_digit} ({confidence:.1f}%)',\n                  fontsize=14, fontweight='bold')\n    ax2.set_xticks(range(10))\n    ax2.grid(True, alpha=0.3, axis='y')\n\n    plt.tight_layout()\n    plt.show()\n\n    print(f\"\\nPredicted Digit: {predicted_digit}\")\n    print(f\"Confidence: {confidence:.2f}%\")\n    print()\n    print(\"All class probabilities:\")\n    for i, prob in enumerate(predictions[0]):\n        marker = \" <-- PREDICTED\" if i == predicted_digit else \"\"\n        print(f\"  Digit {i}: {prob * 100:5.2f}%{marker}\")\n\n    return predicted_digit, confidence\n\n\n# ============================================\n# Choose your method below!\n# Uncomment ONE method and run the cell.\n# ============================================\n\n# ==========================================\n# METHOD A: Upload image from your computer\n# ==========================================\n# Works in Google Colab - shows a \"Choose Files\" button.\n# Supports PNG, JPG, JPEG images.\n\n# try:\n#     from google.colab import files\n#     print(\"METHOD A: Upload Image\")\n#     print(\"=\" * 60)\n#     print(\"Click 'Choose Files' below to upload a handwritten digit image:\")\n#     print()\n#     uploaded = files.upload()\n#\n#     for filename in uploaded.keys():\n#         print(f\"\\nProcessing: {filename}\")\n#         print(\"-\" * 60)\n#\n#         # Load and preprocess\n#         img = Image.open(filename).convert('L')        # Convert to grayscale\n#         img = img.resize((28, 28), Image.Resampling.LANCZOS)  # Resize to 28x28\n#         img_array = np.array(img)\n#\n#         # Auto-invert: if background is bright (white paper), invert colors\n#         # MNIST expects white digit on black background\n#         if img_array.mean() > 127:\n#             print(\"  (Auto-inverted colors: black-on-white -> white-on-black)\")\n#             img_array = 255 - img_array\n#\n#         predict_from_array(img_array)\n#\n# except ImportError:\n#     print(\"Not running on Google Colab. Use Method B or C instead.\")\n\n\n# ==========================================\n# METHOD B: Draw a digit with your mouse\n# ==========================================\n# Creates an interactive canvas in Google Colab.\n# Draw a digit, then click \"Predict\" button.\n\n# try:\n#     from google.colab import output\n#     from IPython.display import HTML, display\n#\n#     print(\"METHOD B: Draw a Digit\")\n#     print(\"=\" * 60)\n#     print(\"Draw a digit (0-9) in the black box below, then click 'Predict'\")\n#     print()\n#\n#     canvas_html = \"\"\"\n#     <div style=\"text-align:center\">\n#     <canvas id=\"canvas\" width=\"280\" height=\"280\"\n#             style=\"border:2px solid #666; cursor:crosshair; background:black;\"></canvas>\n#     <br><br>\n#     <button onclick=\"predict()\" style=\"padding:10px 30px; font-size:16px;\n#             background:#4CAF50; color:white; border:none; border-radius:5px;\n#             cursor:pointer; margin:5px;\">Predict</button>\n#     <button onclick=\"clearCanvas()\" style=\"padding:10px 30px; font-size:16px;\n#             background:#f44336; color:white; border:none; border-radius:5px;\n#             cursor:pointer; margin:5px;\">Clear</button>\n#     </div>\n#\n#     <script>\n#     var canvas = document.getElementById('canvas');\n#     var ctx = canvas.getContext('2d');\n#     var drawing = false;\n#\n#     // Set up drawing style (white pen on black background)\n#     ctx.fillStyle = 'black';\n#     ctx.fillRect(0, 0, 280, 280);\n#     ctx.strokeStyle = 'white';\n#     ctx.lineWidth = 18;\n#     ctx.lineCap = 'round';\n#     ctx.lineJoin = 'round';\n#\n#     canvas.addEventListener('mousedown', function(e) {\n#         drawing = true;\n#         ctx.beginPath();\n#         var rect = canvas.getBoundingClientRect();\n#         ctx.moveTo(e.clientX - rect.left, e.clientY - rect.top);\n#     });\n#\n#     canvas.addEventListener('mousemove', function(e) {\n#         if (drawing) {\n#             var rect = canvas.getBoundingClientRect();\n#             ctx.lineTo(e.clientX - rect.left, e.clientY - rect.top);\n#             ctx.stroke();\n#         }\n#     });\n#\n#     canvas.addEventListener('mouseup', function() { drawing = false; });\n#     canvas.addEventListener('mouseleave', function() { drawing = false; });\n#\n#     // Touch support for mobile/tablet\n#     canvas.addEventListener('touchstart', function(e) {\n#         e.preventDefault();\n#         drawing = true;\n#         ctx.beginPath();\n#         var rect = canvas.getBoundingClientRect();\n#         var touch = e.touches[0];\n#         ctx.moveTo(touch.clientX - rect.left, touch.clientY - rect.top);\n#     });\n#\n#     canvas.addEventListener('touchmove', function(e) {\n#         e.preventDefault();\n#         if (drawing) {\n#             var rect = canvas.getBoundingClientRect();\n#             var touch = e.touches[0];\n#             ctx.lineTo(touch.clientX - rect.left, touch.clientY - rect.top);\n#             ctx.stroke();\n#         }\n#     });\n#\n#     canvas.addEventListener('touchend', function() { drawing = false; });\n#\n#     function clearCanvas() {\n#         ctx.fillStyle = 'black';\n#         ctx.fillRect(0, 0, 280, 280);\n#     }\n#\n#     function predict() {\n#         var dataURL = canvas.toDataURL('image/png');\n#         google.colab.kernel.invokeFunction('notebook.predict_drawn', [dataURL], {});\n#     }\n#     </script>\n#     \"\"\"\n#\n#     def predict_drawn(data_url):\n#         \"\"\"Callback: receives the drawn image from the canvas.\"\"\"\n#         # Decode base64 image data\n#         header, data = data_url.split(',', 1)\n#         image_bytes = base64.b64decode(data)\n#         img = Image.open(io.BytesIO(image_bytes)).convert('L')\n#         img = img.resize((28, 28), Image.Resampling.LANCZOS)\n#         img_array = np.array(img)\n#         predict_from_array(img_array)\n#\n#     output.register_callback('notebook.predict_drawn', predict_drawn)\n#     display(HTML(canvas_html))\n#\n# except ImportError:\n#     print(\"Not running on Google Colab. Use Method C instead.\")\n\n\n# ==========================================\n# METHOD C: Test with random test set image\n# ==========================================\n# No upload needed - picks a random image from the MNIST test set.\n# Run this cell multiple times to see different examples.\n\nprint(\"METHOD C: Random Test Set Image\")\nprint(\"=\" * 60)\nprint(\"Picking a random image from the 10,000 test images...\")\nprint()\n\nrandom_idx = np.random.randint(0, len(X_test))\ntest_image_flat = X_test[random_idx]\nactual_digit = np.argmax(y_test[random_idx])\n\n# Convert back to 28x28 for display (already normalized to 0-1)\ntest_image_2d = (test_image_flat.reshape(28, 28) * 255).astype(np.uint8)\n\nprint(f\"Test image index: {random_idx}\")\nprint(f\"True label: {actual_digit}\")\nprint()\n\npredicted, confidence = predict_from_array(test_image_2d)\n\nprint()\nif predicted == actual_digit:\n    print(f\"CORRECT! Model predicted {predicted}, actual is {actual_digit}\")\nelse:\n    print(f\"WRONG! Model predicted {predicted}, but actual is {actual_digit}\")\nprint(\"=\" * 60)\nprint()\nprint(\"Run this cell again to test another random image!\")"
  },
  {
   "cell_type": "markdown",
   "source": "## Cell 13A: Upload Your Own Image (Google Colab)\nRun this cell to upload a handwritten digit image from your computer.\nThe code **auto-inverts colors** (black-on-white -> white-on-black) to match MNIST format.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================\n# CELL 13A: Upload Image from Your Computer\n# ============================================\n# Run this cell -> Click \"Choose Files\" -> Select your image -> See prediction!\n# ============================================\n\nfrom google.colab import files\n\nprint(\"METHOD A: Upload Image from Your Computer\")\nprint(\"=\" * 60)\nprint(\"Click 'Choose Files' below to upload a handwritten digit image (PNG/JPG):\")\nprint()\n\nuploaded = files.upload()\n\nfor filename in uploaded.keys():\n    print(f\"\\nProcessing: {filename}\")\n    print(\"-\" * 60)\n\n    # Load and preprocess the uploaded image\n    img = Image.open(filename).convert('L')                # Convert to grayscale\n    img = img.resize((28, 28), Image.Resampling.LANCZOS)   # Resize to 28x28\n    img_array = np.array(img)\n\n    # Auto-invert colors if needed\n    # Most handwritten images: black digit on white paper (mean > 127)\n    # MNIST format: white digit on black background (mean < 127)\n    if img_array.mean() > 127:\n        print(\"  (Auto-inverted colors: black-on-white -> white-on-black)\")\n        img_array = 255 - img_array\n\n    predict_from_array(img_array)\n\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Cell 13B: Draw a Digit with Your Mouse (Google Colab)\nRun this cell to get an interactive drawing canvas. Draw a digit with your mouse, then click **\"Predict\"**.\nClick **\"Clear\"** to start over. Works on mobile with touch too!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================\n# CELL 13B: Draw a Digit with Your Mouse\n# ============================================\n# A black canvas appears below. Draw a white digit with your mouse.\n# Click \"Predict\" to see the model's prediction.\n# Click \"Clear\" to erase and try again.\n# ============================================\n\nfrom google.colab import output\nfrom IPython.display import HTML, display\n\nprint(\"METHOD B: Draw a Digit\")\nprint(\"=\" * 60)\nprint(\"Draw a digit (0-9) in the black box below, then click 'Predict'\")\nprint()\n\ncanvas_html = \"\"\"\n<div style=\"text-align:center\">\n<canvas id=\"canvas\" width=\"280\" height=\"280\"\n        style=\"border:2px solid #666; cursor:crosshair; background:black;\"></canvas>\n<br><br>\n<button onclick=\"predict()\" style=\"padding:10px 30px; font-size:16px;\n        background:#4CAF50; color:white; border:none; border-radius:5px;\n        cursor:pointer; margin:5px;\">Predict</button>\n<button onclick=\"clearCanvas()\" style=\"padding:10px 30px; font-size:16px;\n        background:#f44336; color:white; border:none; border-radius:5px;\n        cursor:pointer; margin:5px;\">Clear</button>\n<p style=\"color:#888; margin-top:10px;\">Draw a large, centered digit for best results</p>\n</div>\n\n<script>\nvar canvas = document.getElementById('canvas');\nvar ctx = canvas.getContext('2d');\nvar drawing = false;\n\n// Black background, white pen (matches MNIST format)\nctx.fillStyle = 'black';\nctx.fillRect(0, 0, 280, 280);\nctx.strokeStyle = 'white';\nctx.lineWidth = 18;\nctx.lineCap = 'round';\nctx.lineJoin = 'round';\n\n// Mouse events\ncanvas.addEventListener('mousedown', function(e) {\n    drawing = true;\n    ctx.beginPath();\n    var rect = canvas.getBoundingClientRect();\n    ctx.moveTo(e.clientX - rect.left, e.clientY - rect.top);\n});\n\ncanvas.addEventListener('mousemove', function(e) {\n    if (drawing) {\n        var rect = canvas.getBoundingClientRect();\n        ctx.lineTo(e.clientX - rect.left, e.clientY - rect.top);\n        ctx.stroke();\n    }\n});\n\ncanvas.addEventListener('mouseup', function() { drawing = false; });\ncanvas.addEventListener('mouseleave', function() { drawing = false; });\n\n// Touch events (mobile/tablet)\ncanvas.addEventListener('touchstart', function(e) {\n    e.preventDefault();\n    drawing = true;\n    ctx.beginPath();\n    var rect = canvas.getBoundingClientRect();\n    var touch = e.touches[0];\n    ctx.moveTo(touch.clientX - rect.left, touch.clientY - rect.top);\n});\n\ncanvas.addEventListener('touchmove', function(e) {\n    e.preventDefault();\n    if (drawing) {\n        var rect = canvas.getBoundingClientRect();\n        var touch = e.touches[0];\n        ctx.lineTo(touch.clientX - rect.left, touch.clientY - rect.top);\n        ctx.stroke();\n    }\n});\n\ncanvas.addEventListener('touchend', function() { drawing = false; });\n\nfunction clearCanvas() {\n    ctx.fillStyle = 'black';\n    ctx.fillRect(0, 0, 280, 280);\n}\n\nfunction predict() {\n    var dataURL = canvas.toDataURL('image/png');\n    google.colab.kernel.invokeFunction('notebook.predict_drawn', [dataURL], {});\n}\n</script>\n\"\"\"\n\ndef predict_drawn(data_url):\n    \"\"\"Callback: receives the drawn image from the JavaScript canvas.\"\"\"\n    # Decode base64 image data from canvas\n    header, data = data_url.split(',', 1)\n    image_bytes = base64.b64decode(data)\n\n    # Open as grayscale, resize to 28x28 (MNIST size)\n    img = Image.open(io.BytesIO(image_bytes)).convert('L')\n    img = img.resize((28, 28), Image.Resampling.LANCZOS)\n    img_array = np.array(img)\n\n    predict_from_array(img_array)\n\n# Register the JavaScript -> Python callback\noutput.register_callback('notebook.predict_drawn', predict_drawn)\n\n# Display the canvas\ndisplay(HTML(canvas_html))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 14: Program Summary\n",
    "\n",
    "Recap of everything we accomplished and key learnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 14: Program Summary\n",
    "# ============================================\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"PROGRAM EXECUTION COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"Summary of what we accomplished:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\\u2713 1. GPU Configuration\")\n",
    "print(\"     - Detected and configured GPU for acceleration\")\n",
    "print()\n",
    "print(\"\\u2713 2. Data Loading\")\n",
    "print(\"     - Loaded 60,000 training + 10,000 test images\")\n",
    "print()\n",
    "print(\"\\u2713 3. Sample Preview\")\n",
    "print(\"     - Displayed sample digits (6, 7, 8, 9)\")\n",
    "print()\n",
    "print(\"\\u2713 4. Data Preprocessing\")\n",
    "print(\"     - Normalized, flattened, one-hot encoded\")\n",
    "print()\n",
    "print(\"\\u2713 5. Model Building\")\n",
    "print(\"     - Neural network: 784 \\u2192 128 \\u2192 64 \\u2192 10\")\n",
    "print(f\"     - {model.count_params():,} trainable parameters\")\n",
    "print()\n",
    "print(\"\\u2713 6. Model Compilation\")\n",
    "print(\"     - Adam + Categorical Crossentropy\")\n",
    "print()\n",
    "print(\"\\u2713 7. Model Training\")\n",
    "print(f\"     - {EPOCHS} epochs, batch size {BATCH_SIZE}\")\n",
    "print()\n",
    "print(\"\\u2713 8. Model Evaluation\")\n",
    "print(f\"     - Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"     - Test Loss: {test_loss:.4f}\")\n",
    "print()\n",
    "print(\"\\u2713 9. Visualizations\")\n",
    "print(\"     - Loss curve, Accuracy curve, Confusion matrix\")\n",
    "print()\n",
    "print(\"\\u2713 10. Custom Prediction\")\n",
    "print(\"     - Functions ready for custom image prediction\")\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"Key Learnings:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"1. Neural networks learn by adjusting weights to minimize loss\")\n",
    "print(\"2. Preprocessing (normalization, encoding) is critical for training\")\n",
    "print(\"3. Architecture choices affect model capacity and performance\")\n",
    "print(\"4. Adam optimizer + categorical crossentropy = good for classification\")\n",
    "print(\"5. Test accuracy measures real-world generalization\")\n",
    "print(\"6. Confusion matrix reveals systematic prediction errors\")\n",
    "print()\n",
    "print(\"Next Steps:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"1. Experiment with different architectures (more/fewer layers)\")\n",
    "print(\"2. Try different activation functions (tanh, LeakyReLU)\")\n",
    "print(\"3. Add dropout layers to prevent overfitting\")\n",
    "print(\"4. Implement convolutional layers (CNN) for better accuracy\")\n",
    "print(\"5. Test on your own handwritten digit images\")\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"Thank you for learning with this educational implementation!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ]
}